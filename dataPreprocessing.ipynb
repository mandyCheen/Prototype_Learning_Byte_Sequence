{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading x86_64 dataset from ./dataset/malware_original_x86_64.csv...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import r2pipe as r2\n",
    "from tqdm import tqdm\n",
    "\n",
    "BYTE_LENGTH = 2000\n",
    "N_GRAM_1 = 2\n",
    "N_GRAM_2 = 4\n",
    "N_WAYS = 10\n",
    "SEED = 7\n",
    "NUM_EXAMPLES = 100\n",
    "NUM_EXAMPLES_TEST = 30\n",
    "NUM_EXAMPLES_VAL = 0\n",
    "\n",
    "# load dataset\n",
    "DATASET_PATH = \"./dataset/malware_original_x86_64.csv\"\n",
    "DATASET_FOLDER = \"/home/mandy900619/data/Malware202403/\"\n",
    "CLUSTER_PATH = \"./cluster_data/\"\n",
    "CPU_ARCH = \"x86_64\"  \n",
    "EMBEDDING_PATH = \"./dataset_embedding/\" \n",
    "ADDITONAL_INFO = \"_rm_dup\"\n",
    "\n",
    "print(f\"Loading {CPU_ARCH} dataset from {DATASET_PATH}...\")\n",
    "dataset = pd.read_csv(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract byte sequences from ELF files\n",
    "from elftools.elf.elffile import ELFFile\n",
    "import concurrent.futures\n",
    "\n",
    "notHaveByteSequence = False\n",
    "removeDup = True\n",
    "\n",
    "def split_hex_string(hex_string):\n",
    "    return \" \".join([hex_string[i:i+2] for i in range(0, len(hex_string), 2)])\n",
    "\n",
    "if notHaveByteSequence:\n",
    "    # extract byte sequences\n",
    "    print(f\"Extract byte sequences from {CPU_ARCH} dataset...\")\n",
    "    print(f\"Extracting byte sequences of length {BYTE_LENGTH}...\")\n",
    "\n",
    "    for row in tqdm(dataset.itertuples(), total=len(dataset)):\n",
    "        # open file with r2\n",
    "        byteAnalysis = r2.open(DATASET_FOLDER + row.file_name[:2] + \"/\" + row.file_name, flags=[\"-2\"])\n",
    "        out = byteAnalysis.cmd(f\"px* {BYTE_LENGTH}\")\n",
    "        byteAnalysis.cmd(\"quit\")\n",
    "        lines = out.strip().split(\"\\n\")\n",
    "        byteSeqence = [line[3:-1] for line in lines if not line.startswith(\"s-\")]\n",
    "        byteSeqence = \"\".join(byteSeqence)\n",
    "        byteSeqence = split_hex_string(byteSeqence)\n",
    "        dataset.at[row.Index, \"byte_sequence\"] = byteSeqence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataset\n",
    "if notHaveByteSequence:  \n",
    "    OUTPUT_PATH = f\"./dataset/malware_original_{CPU_ARCH}_byte_sequence{BYTE_LENGTH}_split.csv\"\n",
    "    dataset.to_csv(OUTPUT_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           file_name  \\\n",
      "0  00001167300f0d583aff72a78a99a84a0729f3d159e03f...   \n",
      "1  000071dec3aaadf9759438c65b514c5797a51943ca450e...   \n",
      "2  0000e2fed3bad7d994fd0a25003269ce4531d636a21cec...   \n",
      "3  00011a42ef9e77b80ed66e4f5451726a31314c48ca835f...   \n",
      "4  0001cb07e51b157c2e14d8b2bfdc2e1876b4d91ba519df...   \n",
      "\n",
      "                                md5    label                            CPU  \\\n",
      "0  9961981cacc112f39c0115042582f949  Malware  Advanced Micro Devices X86-64   \n",
      "1  f5475dbe501bf005948235620239b543  Malware  Advanced Micro Devices X86-64   \n",
      "2  d6b2df486692cbf7e088a245e5bb7aea  Malware  Advanced Micro Devices X86-64   \n",
      "3  4f8080a5d1925c43aff40169b123ddb7  Malware  Advanced Micro Devices X86-64   \n",
      "4  661278e864815fa95a2d81b9c7847b98  Malware  Advanced Micro Devices X86-64   \n",
      "\n",
      "    family           first_seen      size  is_packed  packer_info  \\\n",
      "0  ngioweb  2024-01-31 17:32:58   96710.0      False          NaN   \n",
      "1  ngioweb  2023-12-31 17:43:13  185729.0      False          NaN   \n",
      "2  tsunami  2019-05-29 08:03:22   48417.0      False          NaN   \n",
      "3   gafgyt  2022-12-01 00:58:26   44976.0      False          NaN   \n",
      "4  ngioweb  2024-01-17 17:47:08   96632.0      False          NaN   \n",
      "\n",
      "   packing_algorithm  UPX(3.94)  UPX(3.95)  UPX(4.02)  \\\n",
      "0                NaN       True       True       True   \n",
      "1                NaN       True       True       True   \n",
      "2                NaN       True       True       True   \n",
      "3                NaN       True       True       True   \n",
      "4                NaN       True       True       True   \n",
      "\n",
      "                                       byte_sequence  \n",
      "0  48 31 ed 48 89 e7 48 8d 35 08 fe bf ff 48 83 e...  \n",
      "1  48 31 ed 48 89 e7 48 8d 35 08 fe bf ff 48 83 e...  \n",
      "2  31 ed 49 89 d1 5e 48 89 e2 48 83 e4 f0 50 54 4...  \n",
      "3  f3 0f 1e fa 31 ed 49 89 d1 5e 48 89 e2 48 83 e...  \n",
      "4  48 31 ed 48 89 e7 48 8d 35 08 fe bf ff 48 83 e...  \n",
      "Original dataset shape: (122009, 14)\n",
      "Removing duplicate rows based on byte_sequence...\n",
      "Dataset shape after removing duplicates: (34930, 14)\n",
      "family\n",
      "gafgyt          22740\n",
      "mirai            4815\n",
      "tsunami          4635\n",
      "sliver            408\n",
      "camelot           372\n",
      "sshdoor           302\n",
      "dropperl          247\n",
      "xmrig             180\n",
      "rekoobe           165\n",
      "vtflooder         130\n",
      "drtycow           123\n",
      "pnscan             87\n",
      "horsepill          78\n",
      "merlin             77\n",
      "prochider          56\n",
      "revproxy           53\n",
      "aenjaris           49\n",
      "exploitscan        46\n",
      "malsource          42\n",
      "meterpreter        40\n",
      "cleanlog           38\n",
      "hive               33\n",
      "cobaltstrike       33\n",
      "blueshell          31\n",
      "dnsamp             25\n",
      "kaiji              25\n",
      "winnti             23\n",
      "dofloo             16\n",
      "mrblack            15\n",
      "rozena             15\n",
      "ladvix              8\n",
      "chinaz              8\n",
      "ngioweb             6\n",
      "rudedevil           4\n",
      "sotdas              4\n",
      "darktequila         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if removeDup:\n",
    "    dataset = pd.read_csv(f\"./dataset/malware_original_{CPU_ARCH}_byte_sequence{BYTE_LENGTH}_split.csv\")\n",
    "    # remove duplicate rows based on byte_sequence\n",
    "    print(\"Original dataset shape:\", dataset.shape)\n",
    "    print(\"Removing duplicate rows based on byte_sequence...\")\n",
    "    dataset_rm_dup = dataset.drop_duplicates(subset=\"byte_sequence\")\n",
    "    dataset_rm_dup = dataset_rm_dup.reset_index(drop=True)\n",
    "    print(\"Dataset shape after removing duplicates:\", dataset_rm_dup.shape)\n",
    "    family_counts = dataset_rm_dup[\"family\"].value_counts()\n",
    "    print(family_counts[:])\n",
    "\n",
    "    # output dataset\n",
    "    OUTPUT_PATH = f\"./dataset/malware_original_{CPU_ARCH}_byte_sequence{BYTE_LENGTH}_split{ADDITONAL_INFO}.csv\"\n",
    "    dataset_rm_dup.to_csv(OUTPUT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(f\"./dataset/malware_original_{CPU_ARCH}_byte_sequence{BYTE_LENGTH}_split{ADDITONAL_INFO}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33994, 14)\n",
      "(1000, 14)\n",
      "(300, 14)\n"
     ]
    }
   ],
   "source": [
    "family = dataset['family'].value_counts()[:(N_WAYS)].index\n",
    "dataset_exp = dataset[dataset['family'].isin(family)]\n",
    "\n",
    "print(dataset_exp.shape)\n",
    "\n",
    "\n",
    "dataset_train = dataset_exp.groupby('family').sample(n=NUM_EXAMPLES, random_state=SEED)\n",
    "\n",
    "dataset_test = dataset_exp[~dataset_exp.index.isin(dataset_train.index)].groupby('family').sample(n=NUM_EXAMPLES_TEST, random_state=SEED)\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    dataset_val = dataset_exp[~dataset_exp.index.isin(dataset_train.index) & ~dataset_exp.index.isin(dataset_test.index)].groupby('family').sample(n=NUM_EXAMPLES_VAL, random_state=SEED)\n",
    "\n",
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    print(dataset_val.shape)\n",
    "\n",
    "\n",
    "byteSeqenceTrain = dataset_train['byte_sequence'].values\n",
    "byteSeqenceTest = dataset_test['byte_sequence'].values\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    byteSeqenceVal = dataset_val['byte_sequence'].values\n",
    "y_train = dataset_train['family'].values\n",
    "y_test = dataset_test['family'].values\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    y_val = dataset_val['family'].values\n",
    "\n",
    "\n",
    "# convert y family to number\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    list_ = list(y_train) + list(y_test) + list(y_val)\n",
    "else:\n",
    "    list_ = list(y_train) + list(y_test)\n",
    "le.fit(list_)\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    y_val = le.fit_transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tf-idf features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 4-grams\n",
    "tfidf_vec = TfidfVectorizer(analyzer='word', ngram_range=(N_GRAM_1, N_GRAM_2), max_features=1000) # , max_features=1000\n",
    "tfidf_matrix_train = tfidf_vec.fit_transform(byteSeqenceTrain)\n",
    "tfidf_matrix_test = tfidf_vec.transform(byteSeqenceTest)\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    tfidf_matrix_val = tfidf_vec.transform(byteSeqenceVal)\n",
    "\n",
    "tfidf_matrix_train = tfidf_matrix_train.toarray()\n",
    "tfidf_matrix_test = tfidf_matrix_test.toarray()\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    tfidf_matrix_val = tfidf_matrix_val.toarray()\n",
    "\n",
    "label_mapping = {index: label for index, label in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1000, 1000)\n",
      "Testing set shape: (300, 1000)\n",
      "Label mapping: {0: 'camelot', 1: 'dropperl', 2: 'gafgyt', 3: 'mirai', 4: 'rekoobe', 5: 'sliver', 6: 'sshdoor', 7: 'tsunami', 8: 'vtflooder', 9: 'xmrig'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {tfidf_matrix_train.shape}\")\n",
    "print(f\"Testing set shape: {tfidf_matrix_test.shape}\")\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    print(f\"Validation set shape: {tfidf_matrix_val.shape}\")\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_label_mapping{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_mapping, f)\n",
    "    f.close()\n",
    "with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_tfidf_vec_train{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "    pickle.dump(tfidf_matrix_train, f)\n",
    "    f.close()\n",
    "with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_tfidf_vec_test{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "    pickle.dump(tfidf_matrix_test, f)\n",
    "    f.close()\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_tfidf_vec_val{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "        pickle.dump(tfidf_matrix_val, f)\n",
    "        f.close()\n",
    "with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_y_train{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "    f.close()\n",
    "with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_y_test{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "    pickle.dump(y_test, f)\n",
    "    f.close()\n",
    "if NUM_EXAMPLES_VAL > 0:\n",
    "    with open(f\"{EMBEDDING_PATH}{CPU_ARCH}_y_val{ADDITONAL_INFO}.pickle\", 'wb') as f:\n",
    "        pickle.dump(y_val, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format is a vector one line, each dimension value split by blank space\n",
    "# cluster preprocessing\n",
    "for key in label_mapping:\n",
    "    outputPathTrain = f\"{CLUSTER_PATH}{CPU_ARCH}_{label_mapping[key]}_train{ADDITONAL_INFO}.txt\"\n",
    "    # outputPathTest = f\"{CLUSTER_PATH}{CPU_ARCH}_{label_mapping[key]}_test.txt\"\n",
    "    with open(outputPathTrain, 'w') as f:\n",
    "        for i in range(len(tfidf_matrix_train)):\n",
    "            if y_train[i] == key:\n",
    "                f.write('\\t'.join(map(str, tfidf_matrix_train[i])) + \"\\n\")\n",
    "    f.close()\n",
    "    # with open(outputPathTest, 'w') as f:\n",
    "    #     for i in range(len(tfidf_matrix_test)):\n",
    "    #         if y_test[i] == key:\n",
    "    #             f.write('\\t'.join(map(str, tfidf_matrix_test[i])) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
