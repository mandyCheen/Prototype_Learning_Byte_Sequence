{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading x86_64 dataset from ./dataset/malware_original_x86_64_byte_sequence2000_split.csv...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import r2pipe as r2\n",
    "from tqdm import tqdm\n",
    "\n",
    "BYTE_LENGTH = 2000\n",
    "N_GRAM_1 = 2\n",
    "N_GRAM_2 = 4\n",
    "N_WAYS = 10\n",
    "SEED = 7\n",
    "NUM_EXAMPLES = 200\n",
    "NUM_EXAMPLES_TEST = 30\n",
    "\n",
    "# load dataset\n",
    "DATASET_PATH = f\"./dataset/malware_original_x86_64_byte_sequence{BYTE_LENGTH}_split.csv\"\n",
    "DATASET_FOLDER = \"/home/mandy900619/data/Malware202403/\"\n",
    "CLUSTER_PATH = \"./cluster_data/\"\n",
    "TSNE_PATH = \"./pic/\"\n",
    "MODEL_PATH = \"./models/\"\n",
    "LOG_PATH = \"./logs/\"\n",
    "CPU_ARCH = \"x86_64\"   \n",
    "\n",
    "print(f\"Loading {CPU_ARCH} dataset from {DATASET_PATH}...\")\n",
    "dataset = pd.read_csv(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119454, 14)\n",
      "(2000, 14)\n",
      "(300, 14)\n"
     ]
    }
   ],
   "source": [
    "family = dataset['family'].value_counts()[:(N_WAYS)].index\n",
    "dataset_exp = dataset[dataset['family'].isin(family)]\n",
    "\n",
    "print(dataset_exp.shape)\n",
    "\n",
    "\n",
    "dataset_train = dataset_exp.groupby('family').sample(n=NUM_EXAMPLES, random_state=SEED)\n",
    "\n",
    "dataset_test = dataset_exp[~dataset_exp.index.isin(dataset_train.index)].groupby('family').sample(n=NUM_EXAMPLES_TEST, random_state=SEED)\n",
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)\n",
    "\n",
    "\n",
    "byteSeqenceTrain = dataset_train['byte_sequence'].values\n",
    "byteSeqenceTest = dataset_test['byte_sequence'].values\n",
    "y_train = dataset_train['family'].values\n",
    "y_test = dataset_test['family'].values\n",
    "\n",
    "\n",
    "# convert y family to number\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y_train) + list(y_test))\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tf-idf features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 4-grams\n",
    "tfidf_vec = TfidfVectorizer(analyzer='word', ngram_range=(N_GRAM_1, N_GRAM_2), max_features=1000) # , max_features=1000\n",
    "tfidf_matrix_train = tfidf_vec.fit_transform(byteSeqenceTrain)\n",
    "tfidf_matrix_test = tfidf_vec.transform(byteSeqenceTest)\n",
    "\n",
    "tfidf_matrix_train = tfidf_matrix_train.toarray()\n",
    "tfidf_matrix_test = tfidf_matrix_test.toarray()\n",
    "\n",
    "label_mapping = {index: label for index, label in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2000, 1000)\n",
      "Testing set shape: (300, 1000)\n",
      "Label mapping: {0: 'camelot', 1: 'gafgyt', 2: 'meterpreter', 3: 'mirai', 4: 'ngioweb', 5: 'rekoobe', 6: 'sliver', 7: 'sshdoor', 8: 'tsunami', 9: 'xmrig'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape: {tfidf_matrix_train.shape}\")\n",
    "print(f\"Testing set shape: {tfidf_matrix_test.shape}\")\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format is a vector one line, each dimension value split by blank space\n",
    "for key in label_mapping:\n",
    "    outputPathTrain = f\"{CLUSTER_PATH}{CPU_ARCH}_{label_mapping[key]}_train.txt\"\n",
    "    outputPathTest = f\"{CLUSTER_PATH}{CPU_ARCH}_{label_mapping[key]}_test.txt\"\n",
    "    with open(outputPathTrain, 'w') as f:\n",
    "        for i in range(len(tfidf_matrix_train)):\n",
    "            if y_train[i] == key:\n",
    "                f.write('\\t'.join(map(str, tfidf_matrix_train[i])) + \"\\n\")\n",
    "    with open(outputPathTest, 'w') as f:\n",
    "        for i in range(len(tfidf_matrix_test)):\n",
    "            if y_test[i] == key:\n",
    "                f.write('\\t'.join(map(str, tfidf_matrix_test[i])) + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"{CPU_ARCH}_label_mapping.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_mapping, f)\n",
    "    f.close()\n",
    "with open(f\"{CPU_ARCH}_tfidf_vec_train.pickle\", 'wb') as f:\n",
    "    pickle.dump(tfidf_matrix_train, f)\n",
    "    f.close()\n",
    "with open(f\"{CPU_ARCH}_tfidf_vec_test.pickle\", 'wb') as f:\n",
    "    pickle.dump(tfidf_matrix_test, f)\n",
    "    f.close()\n",
    "with open(f\"{CPU_ARCH}_y_train.pickle\", 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "    f.close()\n",
    "with open(f\"{CPU_ARCH}_y_test.pickle\", 'wb') as f:\n",
    "    pickle.dump(y_test, f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
