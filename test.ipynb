{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for fc1.weight: tensor([[ 0.0154,  0.0078,  0.0122,  0.0068,  0.0234, -0.0251, -0.0100,  0.0292,\n",
      "         -0.0118,  0.0124],\n",
      "        [ 0.0030,  0.0111,  0.0062, -0.0031,  0.0653, -0.0474,  0.0029,  0.0271,\n",
      "         -0.0054,  0.0041],\n",
      "        [-0.0215,  0.0037, -0.0113,  0.0147,  0.0382, -0.0259,  0.0087,  0.0224,\n",
      "         -0.0029, -0.0032],\n",
      "        [-0.0089,  0.0059,  0.0003, -0.0087,  0.0096,  0.0038,  0.0018, -0.0015,\n",
      "          0.0015, -0.0028],\n",
      "        [ 0.0115,  0.0098,  0.0053, -0.0023, -0.0373,  0.0226, -0.0085, -0.0081,\n",
      "          0.0111, -0.0003]])\n",
      "Gradient for fc1.bias: tensor([ 0.0114,  0.0353,  0.0353,  0.0021, -0.0202])\n",
      "Gradient for fc2.weight: tensor([[ 0.1071,  0.0866,  0.0399,  0.0201,  0.0583],\n",
      "        [-0.1071, -0.0866, -0.0399, -0.0201, -0.0583]])\n",
      "Gradient for fc2.bias: tensor([ 0.1718, -0.1718])\n",
      "<generator object Module.parameters at 0x7f19ee39e340>\n",
      "Gradient for fc1.weight after epoch 0: tensor([[ 0.0154,  0.0078,  0.0122,  0.0068,  0.0234, -0.0251, -0.0100,  0.0292,\n",
      "         -0.0118,  0.0124],\n",
      "        [ 0.0030,  0.0111,  0.0062, -0.0031,  0.0653, -0.0474,  0.0029,  0.0271,\n",
      "         -0.0054,  0.0041],\n",
      "        [-0.0215,  0.0037, -0.0113,  0.0147,  0.0382, -0.0259,  0.0087,  0.0224,\n",
      "         -0.0029, -0.0032],\n",
      "        [-0.0089,  0.0059,  0.0003, -0.0087,  0.0096,  0.0038,  0.0018, -0.0015,\n",
      "          0.0015, -0.0028],\n",
      "        [ 0.0115,  0.0098,  0.0053, -0.0023, -0.0373,  0.0226, -0.0085, -0.0081,\n",
      "          0.0111, -0.0003]])\n",
      "Gradient for fc1.bias after epoch 0: tensor([ 0.0114,  0.0353,  0.0353,  0.0021, -0.0202])\n",
      "Gradient for fc2.weight after epoch 0: tensor([[ 0.1071,  0.0866,  0.0399,  0.0201,  0.0583],\n",
      "        [-0.1071, -0.0866, -0.0399, -0.0201, -0.0583]])\n",
      "Gradient for fc2.bias after epoch 0: tensor([ 0.1718, -0.1718])\n",
      "Gradient for fc1.weight after epoch 1: tensor([[ 0.0154,  0.0077,  0.0121,  0.0066,  0.0231, -0.0248, -0.0098,  0.0287,\n",
      "         -0.0117,  0.0122],\n",
      "        [ 0.0030,  0.0110,  0.0063, -0.0032,  0.0647, -0.0469,  0.0029,  0.0267,\n",
      "         -0.0054,  0.0042],\n",
      "        [-0.0202, -0.0047, -0.0115,  0.0104,  0.0347, -0.0177,  0.0105,  0.0184,\n",
      "          0.0026, -0.0032],\n",
      "        [-0.0087,  0.0058,  0.0003, -0.0084,  0.0094,  0.0037,  0.0018, -0.0015,\n",
      "          0.0015, -0.0027],\n",
      "        [ 0.0117,  0.0099,  0.0053, -0.0023, -0.0377,  0.0228, -0.0086, -0.0081,\n",
      "          0.0112, -0.0004]])\n",
      "Gradient for fc1.bias after epoch 1: tensor([ 0.0111,  0.0347,  0.0309,  0.0020, -0.0202])\n",
      "Gradient for fc2.weight after epoch 1: tensor([[ 0.1056,  0.0853,  0.0384,  0.0190,  0.0584],\n",
      "        [-0.1056, -0.0853, -0.0384, -0.0190, -0.0584]])\n",
      "Gradient for fc2.bias after epoch 1: tensor([ 0.1701, -0.1701])\n",
      "Gradient for fc1.weight after epoch 2: tensor([[ 0.0153,  0.0075,  0.0120,  0.0065,  0.0228, -0.0245, -0.0097,  0.0283,\n",
      "         -0.0115,  0.0120],\n",
      "        [ 0.0030,  0.0109,  0.0064, -0.0032,  0.0640, -0.0464,  0.0029,  0.0262,\n",
      "         -0.0054,  0.0042],\n",
      "        [-0.0200, -0.0046, -0.0113,  0.0103,  0.0343, -0.0175,  0.0103,  0.0181,\n",
      "          0.0025, -0.0030],\n",
      "        [-0.0085,  0.0056,  0.0003, -0.0082,  0.0092,  0.0036,  0.0018, -0.0015,\n",
      "          0.0014, -0.0026],\n",
      "        [ 0.0119,  0.0099,  0.0053, -0.0023, -0.0381,  0.0230, -0.0087, -0.0081,\n",
      "          0.0113, -0.0005]])\n",
      "Gradient for fc1.bias after epoch 2: tensor([ 0.0108,  0.0340,  0.0304,  0.0019, -0.0202])\n",
      "Gradient for fc2.weight after epoch 2: tensor([[ 0.1041,  0.0840,  0.0369,  0.0179,  0.0584],\n",
      "        [-0.1041, -0.0840, -0.0369, -0.0179, -0.0584]])\n",
      "Gradient for fc2.bias after epoch 2: tensor([ 0.1685, -0.1685])\n",
      "Gradient for fc1.weight after epoch 3: tensor([[ 0.0152,  0.0073,  0.0119,  0.0063,  0.0224, -0.0241, -0.0095,  0.0279,\n",
      "         -0.0114,  0.0118],\n",
      "        [ 0.0049,  0.0218,  0.0101, -0.0050,  0.0534, -0.0389, -0.0008,  0.0235,\n",
      "          0.0012,  0.0101],\n",
      "        [-0.0198, -0.0045, -0.0111,  0.0102,  0.0338, -0.0173,  0.0102,  0.0178,\n",
      "          0.0025, -0.0029],\n",
      "        [-0.0083,  0.0055,  0.0003, -0.0080,  0.0090,  0.0035,  0.0017, -0.0015,\n",
      "          0.0014, -0.0024],\n",
      "        [ 0.0121,  0.0100,  0.0052, -0.0023, -0.0385,  0.0232, -0.0088, -0.0081,\n",
      "          0.0113, -0.0006]])\n",
      "Gradient for fc1.bias after epoch 3: tensor([ 0.0105,  0.0290,  0.0298,  0.0018, -0.0203])\n",
      "Gradient for fc2.weight after epoch 3: tensor([[ 0.1026,  0.0828,  0.0354,  0.0168,  0.0585],\n",
      "        [-0.1026, -0.0828, -0.0354, -0.0168, -0.0585]])\n",
      "Gradient for fc2.bias after epoch 3: tensor([ 0.1669, -0.1669])\n",
      "Gradient for fc1.weight after epoch 4: tensor([[ 0.0151,  0.0072,  0.0118,  0.0062,  0.0221, -0.0238, -0.0093,  0.0275,\n",
      "         -0.0113,  0.0116],\n",
      "        [ 0.0049,  0.0216,  0.0102, -0.0050,  0.0529, -0.0385, -0.0007,  0.0230,\n",
      "          0.0012,  0.0101],\n",
      "        [-0.0197, -0.0043, -0.0110,  0.0101,  0.0334, -0.0170,  0.0101,  0.0174,\n",
      "          0.0024, -0.0027],\n",
      "        [-0.0081,  0.0054,  0.0003, -0.0078,  0.0088,  0.0034,  0.0017, -0.0015,\n",
      "          0.0013, -0.0023],\n",
      "        [ 0.0122,  0.0101,  0.0052, -0.0023, -0.0389,  0.0234, -0.0089, -0.0081,\n",
      "          0.0114, -0.0007]])\n",
      "Gradient for fc1.bias after epoch 4: tensor([ 0.0102,  0.0284,  0.0293,  0.0017, -0.0203])\n",
      "Gradient for fc2.weight after epoch 4: tensor([[ 0.1012,  0.0816,  0.0339,  0.0157,  0.0586],\n",
      "        [-0.1012, -0.0816, -0.0339, -0.0157, -0.0586]])\n",
      "Gradient for fc2.bias after epoch 4: tensor([ 0.1652, -0.1652])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = SimpleModel()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy data\n",
    "inputs = torch.randn(32, 10)\n",
    "labels = torch.randint(0, 2, (32,))\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "loss = loss_fn(outputs, labels)\n",
    "\n",
    "# Backward pass\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is None:\n",
    "        print(f\"No gradient for {name}\")\n",
    "    else:\n",
    "        print(f\"Gradient for {name}: {param.grad}\")\n",
    "\n",
    "# Ensure optimizer is linked to model parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model.parameters())\n",
    "# Training loop with gradient check\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Check gradients\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is None:\n",
    "            print(f\"No gradient for {name} after epoch {epoch}\")\n",
    "        else:\n",
    "            print(f\"Gradient for {name} after epoch {epoch}: {param.grad}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byteSequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
